<!DOCTYPE html>
<html>
<body>

<h1 style="font-family:Arial; text-align:center;">/home</h1>
<center><img src="background.gif" alt="graphs" width="375" height="150"></center>

<p style="font-family:Verdana; text-align:center;">Welcome to my github site and blog! </p>

<center><a style="font-family:Arial;" href="build/hello-world.html"> click here to read my /blog </a></center>
<br>

<p style="font-size:125%; font-family:Verdana; text-align:center;"> <strong>more about me</strong></p>

<center>
<p style="align=center; font-size:90%; font-family:Verdana;""> I study Cognitive Science (Computation Track) at the University of Michigan with a minor in Complex Systems and Computer Science.
My interests lie in alternative computational models for intelligence, mass social patterns, chaotic/emergent systems, and linguistics.
Most of my past experience has been with neural networks, mostly in the domain of memory networks, von-neumann inspired models (neural turing machine,
differentiable computing devices, neural gpu), transformer models, and image segmentation. <strong>However</strong>, I've also spent the last few years moving away from neural nets.
I've never been a fan of jacking up neural nets e.g. stuffing them with nearly illegal amounts of data and improving relatively insignificant optimizations using climate change
inducing amounts of electricity.
<strong>Yes. I am calling out GPT-x.x here.</strong>
I have taken up a lot of interest in symbolic systems, reinforcement learning, and work that synthesizes neural nets with more traditional paradigms.
I believe that research on more plausible models of human/animal cognitive processes, radical alternative models for intelligent behaviour, emergent social phenomenon,
and computational structures of language will eventually lead us out of this strange hamster wheel we currently find AI in.</p>
</center>
</body>
</html>
